{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb43090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69955c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(trainfile='MNIST_train.csv', validationfile='MNIST_validation.csv'):\n",
    "    \n",
    "    dftrain = pd.read_csv(trainfile)\n",
    "    dfval = pd.read_csv(validationfile)\n",
    "\n",
    "    featurecols = list(dftrain.columns)\n",
    "    featurecols.remove('label')\n",
    "    featurecols.remove('even')\n",
    "\n",
    "    targetcol1 = 'label'\n",
    "    targetcol2 = 'even'\n",
    "\n",
    "    Xtrain = dftrain[featurecols]\n",
    "    ytrain = dftrain[targetcol1]\n",
    "    ytrain2 = dftrain[targetcol2]\n",
    "    \n",
    "    Xval = dfval[featurecols]\n",
    "    yval = dfval[targetcol1]\n",
    "    yval2 = dfval[targetcol2]\n",
    "\n",
    "    return (Xtrain, ytrain, Xval, yval, ytrain2, yval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d967558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xval, yval, ytrain_oe, yval_oe = read_data('MNIST_train.csv', 'MNIST_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0bc410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \"\"\"PCA class that can be fitted once and reused\"\"\"\n",
    "    def __init__(self, variance_threshold=0.95, n_components=None):\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance_ratio = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on training data only\"\"\"\n",
    "        # Normalize and center data\n",
    "        X_normalized = np.array(X, dtype=float) / 255.0\n",
    "        self.mean = np.mean(X_normalized, axis=0)\n",
    "        X_centered = X_normalized - self.mean\n",
    "        \n",
    "        # Compute covariance matrix and eigen decomposition\n",
    "        evd_matrix = (X_centered.T @ X_centered) / (X_centered.shape[0] - 1)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(evd_matrix)\n",
    "        \n",
    "        # Sort by descending eigenvalues\n",
    "        sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues_sorted = eigenvalues[sorted_idx]\n",
    "        eigenvectors_sorted = eigenvectors[:, sorted_idx]\n",
    "        \n",
    "        # Determine components for target variance\n",
    "        self.explained_variance_ratio = eigenvalues_sorted / np.sum(eigenvalues_sorted)\n",
    "        cumulative_variance = np.cumsum(self.explained_variance_ratio)\n",
    "\n",
    "        if self.n_components is None:\n",
    "            self.n_components = np.argmax(cumulative_variance >= self.variance_threshold) + 1\n",
    "        \n",
    "        # Store components\n",
    "        self.components = eigenvectors_sorted[:, :self.n_components]\n",
    "        \n",
    "        print(f\"PCA fitted with {self.n_components} components, explaining {cumulative_variance[self.n_components-1]:.4f} variance\")\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data using fitted PCA\"\"\"\n",
    "        if self.components is None:\n",
    "            raise ValueError(\"PCA must be fitted before transforming\")\n",
    "            \n",
    "        # Apply same normalization and centering\n",
    "        X_normalized = np.array(X, dtype=float) / 255.0\n",
    "        X_centered = X_normalized - self.mean\n",
    "        \n",
    "        # Project to PCA space\n",
    "        return X_centered @ self.components\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13e9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=5, distance_metric='euclidean', weights='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.asarray(X)\n",
    "        self.y_train = np.asarray(y)\n",
    "        self.classes = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def _compute_all_distances(self, X):\n",
    "        \"\"\"\n",
    "        Compute distances between X (n_test × d) and train (n_train × d)\n",
    "        Fully vectorized\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            # (x - y)^2 = x^2 + y^2 - 2xy\n",
    "            X2 = np.sum(X**2, axis=1).reshape(-1, 1)\n",
    "            T2 = np.sum(self.X_train**2, axis=1).reshape(1, -1)\n",
    "            dist = np.sqrt(np.maximum(X2 + T2 - 2 * X @ self.X_train.T, 0))\n",
    "\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            # |x - y|\n",
    "            # Use broadcasting\n",
    "            dist = np.sum(np.abs(X[:, None, :] - self.X_train[None, :, :]), axis=2)\n",
    "\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            # 1 - cosine similarity\n",
    "            X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-15)\n",
    "            T_norm = self.X_train / (np.linalg.norm(self.X_train, axis=1, keepdims=True) + 1e-15)\n",
    "            dist = 1 - X_norm @ T_norm.T\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported metric\")\n",
    "\n",
    "        return dist\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        # vectorized distance computation\n",
    "        dist = self._compute_all_distances(X)\n",
    "\n",
    "        # get k nearest neighbors\n",
    "        idx = np.argpartition(dist, self.k, axis=1)[:, :self.k]\n",
    "        neighbors = self.y_train[idx]\n",
    "\n",
    "        if self.weights == 'uniform':\n",
    "            # majority vote\n",
    "            return np.array([Counter(row).most_common(1)[0][0] for row in neighbors])\n",
    "\n",
    "        else:  # distance-weighted\n",
    "            kdist = np.take_along_axis(dist, idx, axis=1)\n",
    "            weights = 1.0 / (kdist + 1e-15)\n",
    "            preds = []\n",
    "            for lbls, w in zip(neighbors, weights):\n",
    "                vote = {}\n",
    "                for label, weight in zip(lbls, w):\n",
    "                    vote[label] = vote.get(label, 0) + weight\n",
    "                preds.append(max(vote.items(), key=lambda a: a[1])[0])\n",
    "            return np.array(preds)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X)\n",
    "        dist = self._compute_all_distances(X)\n",
    "\n",
    "        idx = np.argpartition(dist, self.k, axis=1)[:, :self.k]\n",
    "        neighbors = self.y_train[idx]\n",
    "\n",
    "        probs = np.zeros((len(X), len(self.classes)))\n",
    "\n",
    "        for i, row in enumerate(neighbors):\n",
    "            for j, cls in enumerate(self.classes):\n",
    "                probs[i, j] = np.sum(row == cls) / self.k\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2b1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def hyperparameter_tuning(Xtrain, ytrain, Xval, yval):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning for custom PCA + custom KNN using WEIGHTED F1.\n",
    "    \"\"\"\n",
    "\n",
    "    k_values = [1, 3, 5, 7, 9, 11, 15, 21]\n",
    "    n_components_values = [10, 20, 30, 50, 75, 100, 150, 200]\n",
    "\n",
    "    distance_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "    weights_options = ['uniform', 'distance']\n",
    "\n",
    "    results = []\n",
    "    best_f1 = 0\n",
    "    best_params = {}\n",
    "\n",
    "    print(\"\\n========== Hyperparameter Tuning (Weighted F1) ==========\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Phase 1: Tune PCA n_components with fixed k=5\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\nPhase 1: Selecting best PCA dimension...\")\n",
    "    pca_phase_results = []\n",
    "\n",
    "    for n_components in n_components_values:\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "        Xtrain_pca = pca.fit_transform(Xtrain)\n",
    "        Xval_pca = pca.transform(Xval)\n",
    "\n",
    "        knn = KNN(k=5, distance_metric='euclidean', weights='uniform')\n",
    "        knn.fit(Xtrain_pca, ytrain)\n",
    "        ypred = knn.predict(Xval_pca)\n",
    "\n",
    "        f1 = f1_score(yval, ypred, average='weighted')\n",
    "\n",
    "        pca_phase_results.append({\"n_components\": n_components, \"f1\": f1})\n",
    "\n",
    "        print(f\"PCA={n_components:4d} | F1={f1:.4f}\")\n",
    "\n",
    "    best_pca = max(pca_phase_results, key=lambda x: x[\"f1\"])\n",
    "    optimal_n_components = best_pca[\"n_components\"]\n",
    "\n",
    "    print(f\"\\n>>> Best PCA Components: {optimal_n_components}\\n\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Phase 2: Tune k using best PCA dim\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\nPhase 2: Tuning k values...\")\n",
    "\n",
    "    pca_fixed = PCA(n_components=optimal_n_components)\n",
    "    Xtrain_pca_fixed = pca_fixed.fit_transform(Xtrain)\n",
    "    Xval_pca_fixed = pca_fixed.transform(Xval)\n",
    "\n",
    "    for k in k_values:\n",
    "\n",
    "        knn = KNN(k=k, distance_metric='euclidean', weights='uniform')\n",
    "        knn.fit(Xtrain_pca_fixed, ytrain)\n",
    "        ypred = knn.predict(Xval_pca_fixed)\n",
    "\n",
    "        f1 = f1_score(yval, ypred, average='weighted')\n",
    "\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"n_components\": optimal_n_components,\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"weights\": \"uniform\",\n",
    "            \"f1\": f1\n",
    "        })\n",
    "\n",
    "        print(f\"k={k:3d} | F1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = {\n",
    "                \"k\": k,\n",
    "                \"n_components\": optimal_n_components,\n",
    "                \"distance_metric\": \"euclidean\",\n",
    "                \"weights\": \"uniform\"\n",
    "            }\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Phase 3: Tune distance metric + weights using best k, best PCA dim\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\nPhase 3: Tuning distance metrics & weights...\")\n",
    "\n",
    "    for dist in distance_metrics:\n",
    "        for w in weights_options:\n",
    "\n",
    "            knn = KNN(k=best_params[\"k\"], distance_metric=dist, weights=w)\n",
    "            knn.fit(Xtrain_pca_fixed, ytrain)\n",
    "            ypred = knn.predict(Xval_pca_fixed)\n",
    "\n",
    "            f1 = f1_score(yval, ypred, average='weighted')\n",
    "\n",
    "            results.append({\n",
    "                \"k\": best_params[\"k\"],\n",
    "                \"n_components\": optimal_n_components,\n",
    "                \"distance_metric\": dist,\n",
    "                \"weights\": w,\n",
    "                \"f1\": f1\n",
    "            })\n",
    "\n",
    "            print(f\"k={best_params['k']:3d} | metric={dist:10} | weights={w:8} | F1={f1:.4f}\")\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\n",
    "                    \"k\": best_params[\"k\"],\n",
    "                    \"n_components\": optimal_n_components,\n",
    "                    \"distance_metric\": dist,\n",
    "                    \"weights\": w\n",
    "                }\n",
    "\n",
    "    print(\"\\n========== BEST PARAMETERS ==========\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Weighted F1: {best_f1:.4f}\")\n",
    "    print(\"=====================================\\n\")\n",
    "\n",
    "    return results, best_params, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6c027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Hyperparameter Tuning (Weighted F1) ==========\n",
      "\n",
      "Phase 1: Selecting best PCA dimension...\n",
      "PCA fitted with 10 components, explaining 0.4869 variance\n",
      "PCA=  10 | F1=0.9058\n",
      "PCA fitted with 20 components, explaining 0.6434 variance\n",
      "PCA=  20 | F1=0.9563\n",
      "PCA fitted with 30 components, explaining 0.7306 variance\n",
      "PCA=  30 | F1=0.9583\n",
      "PCA fitted with 50 components, explaining 0.8254 variance\n",
      "PCA=  50 | F1=0.9579\n",
      "PCA fitted with 75 components, explaining 0.8837 variance\n",
      "PCA=  75 | F1=0.9563\n",
      "PCA fitted with 100 components, explaining 0.9156 variance\n",
      "PCA= 100 | F1=0.9543\n",
      "PCA fitted with 150 components, explaining 0.9492 variance\n",
      "PCA= 150 | F1=0.9539\n",
      "PCA fitted with 200 components, explaining 0.9672 variance\n",
      "PCA= 200 | F1=0.9515\n",
      "\n",
      ">>> Best PCA Components: 30\n",
      "\n",
      "\n",
      "Phase 2: Tuning k values...\n",
      "PCA fitted with 30 components, explaining 0.7306 variance\n",
      "k=  1 | F1=0.9583\n",
      "k=  3 | F1=0.9559\n",
      "k=  5 | F1=0.9583\n",
      "k=  7 | F1=0.9571\n",
      "k=  9 | F1=0.9571\n",
      "k= 11 | F1=0.9543\n",
      "k= 15 | F1=0.9530\n",
      "k= 21 | F1=0.9478\n",
      "\n",
      "Phase 3: Tuning distance metrics & weights...\n",
      "k=  1 | metric=euclidean  | weights=uniform  | F1=0.9583\n",
      "k=  1 | metric=euclidean  | weights=distance | F1=0.9583\n",
      "k=  1 | metric=manhattan  | weights=uniform  | F1=0.9551\n",
      "k=  1 | metric=manhattan  | weights=distance | F1=0.9551\n",
      "k=  1 | metric=cosine     | weights=uniform  | F1=0.9521\n",
      "k=  1 | metric=cosine     | weights=distance | F1=0.9521\n",
      "\n",
      "========== BEST PARAMETERS ==========\n",
      "{'k': 1, 'n_components': 30, 'distance_metric': 'euclidean', 'weights': 'uniform'}\n",
      "Best Weighted F1: 0.9583\n",
      "=====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, best_params, best_f1 = hyperparameter_tuning(Xtrain, ytrain, Xval, yval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
